{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6RdcOuzSr8Lx6vpvrsZ02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muditsatija08/nlp/blob/main/Etivity_6_23256087.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's define the following terms:\n",
        "\n",
        "- TP (True Positive): The number of instances correctly classified as the positive class.\n",
        "- TN (True Negative): The number of instances correctly classified as the negative class.\n",
        "- FP (False Positive): The number of instances incorrectly classified as the positive class.\n",
        "- FN (False Negative): The number of instances incorrectly classified as the negative class.\n",
        "\n",
        "For the \"food\" class:\n",
        "\n",
        "$$TP_{food} = 800, \\quad TN_{food} = 500, \\quad FP_{food} = 200, \\quad FN_{food} = 200$$\n",
        "\n",
        "For the \"drink\" class:\n",
        "\n",
        "$$TP_{drink} = 70, \\quad TN_{drink} = 100, \\quad FP_{drink} = 30, \\quad FN_{drink} = 30$$\n",
        "\n",
        "Now, let's calculate precision, recall, and F1 for each class:\n",
        "\n",
        "$$Precision_{food} = \\frac{TP_{food}}{TP_{food} + FP_{food}} \\\\\n",
        " = \\frac{800}{\\text{800} + \\text{200}} \\\\\n",
        " = 0.8$$\n",
        "\n",
        "$$Recall_{food} = \\frac{TP_{food}}{TP_{food} + FN_{food}} \\\\\n",
        " = \\frac{800}{800 + 200} \\\\\n",
        " = 0.8$$\n",
        "\n",
        "$$F1_{food} = \\frac{2 \\times Precision_{food} \\times Recall_{food}}{Precision_{food} + Recall_{food}} \\\\\n",
        " = \\frac{2 \\times 0.8 \\times 0.8}{0.8 + 0.8} \\\\\n",
        " = \\frac{1.28}{1.6} \\\\\n",
        " = 0.8$$\n",
        "\n",
        "$$Precision_{drink} = \\frac{TP_{drink}}{TP_{drink} + FP_{drink}} \\\\\n",
        " = \\frac{70}{70 + 30} \\\\\n",
        " = 0.7$$\n",
        "\n",
        "$$Recall_{drink} = \\frac{TP_{drink}}{TP_{drink} + FN_{drink}} \\\\\n",
        " = \\frac{70}{70 + 30} \\\\\n",
        " = 0.7$$\n",
        "\n",
        "$$F1_{drink} = \\frac{2 \\times Precision_{drink} \\times Recall_{drink}}{Precision_{drink} + Recall_{drink}} \\\\\n",
        " = \\frac{2 \\times 0.7 \\times 0.7}{0.7 + 0.7} \\\\\n",
        " = 0.7$$\n",
        "\n",
        "Now, Lets calculate micro-averaged and macro-averaged values:\n",
        "\n",
        "Micro-averaged precision, recall, and F1:\n",
        "\n",
        "$$MicroPrecision = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FP_i} \\\\\n",
        " = \\frac{800 + 70}{800 + 200 + 70 + 30} \\\\\n",
        " = \\frac{870}{1100} \\\\\n",
        " = 0.790$$\n",
        "$$MicroRecall = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FN_i} \\\\\n",
        "  = \\frac{800 + 70}{800 + 200 + 30 + 100} \\\\\n",
        "   = \\frac{870}{1130} \\\\\n",
        "   = 0.769$$\n",
        "$$MicroF1 = \\frac{2 \\times MicroPrecision \\times MicroRecall}{MicroPrecision + MicroRecall}\n",
        " = \\frac{2 \\times 0.790 \\times 0.769}{0.790 + 0.769} \\\\\n",
        " = 0.779$$\n",
        "\n",
        "Macro-averaged precision, recall, and F1:\n",
        "\n",
        "$$MacroPrecision = \\frac{1}{N} \\sum_{i} Precision_i \\\\\n",
        " = \\frac{0.8 + 0.7}{2} \\\\\n",
        " = \\frac{1.5}{2} \\\\\n",
        " = 0.75$$\n",
        "$$MacroRecall = \\frac{1}{N} \\sum_{i} Recall_i \\\\\n",
        " = \\frac{0.8 + 0.7}{2} \\\\\n",
        " = \\frac{1.5}{2} \\\\\n",
        " = 0.75$$\n",
        "$$MacroF1 = \\frac{1}{N} \\sum_{i} F1_i \\\\\n",
        " = \\frac{0.8 + 0.7}{2} \\\\\n",
        " = \\frac{1.5}{2} \\\\\n",
        " = 0.75$$\n",
        "\n",
        "Micro-averaged precision = 0.790, Micro-averaged recall = 0.769, Micro-averaged F1 = 0.779\n",
        "\n",
        "Macro-averaged precision = 0.75, Macro-averaged recall = 0.75, Macro-averaged F1 = 0.75\n",
        "\n",
        "Here, \\( N \\) is the number of classes (2 in this case)."
      ],
      "metadata": {
        "id": "Ahg0ppm6oKvQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Krlb3o60jTfG"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "\n",
        "def sentimentAnalyzer(string):\n",
        "  print(f\"string = {string}\")\n",
        "\n",
        "  tb = TextBlob(string)\n",
        "\n",
        "  print(f\"\\n{tb.sentiment}\")\n",
        "\n",
        "\n",
        "  if tb.sentiment.polarity >= -0.1 and tb.sentiment.polarity <= 0.1:\n",
        "      print(\"neutral sentiment ðŸ˜‘\")\n",
        "  elif tb.sentiment.polarity > 0 :\n",
        "    print(\"positive sentiment ðŸ˜Š\")\n",
        "  elif tb.sentiment.polarity < 0:\n",
        "    print(\"negative sentiment ðŸ˜ž\")\n",
        "\n",
        "  print(f\"Subjectivity : {tb.sentiment.subjectivity}\")\n",
        "  print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentAnalyzer('NLP is cool')\n",
        "sentimentAnalyzer(\"NLP is cool and useful\")\n",
        "sentimentAnalyzer(\"NLP is hard\")\n",
        "sentimentAnalyzer(\"NLP is hard and useless\")\n",
        "sentimentAnalyzer(\"NLP stands for Natural Language Processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2hVNbHIABIN",
        "outputId": "af7b22bb-6208-48d8-cb76-9cb02e96454c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "string = NLP is cool\n",
            "\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "positive sentiment ðŸ˜Š\n",
            "Subjectivity : 0.65\n",
            "----------------------------------------------------------------------------------------------------\n",
            "string = NLP is cool and useful\n",
            "\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "positive sentiment ðŸ˜Š\n",
            "Subjectivity : 0.325\n",
            "----------------------------------------------------------------------------------------------------\n",
            "string = NLP is hard\n",
            "\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "negative sentiment ðŸ˜ž\n",
            "Subjectivity : 0.5416666666666666\n",
            "----------------------------------------------------------------------------------------------------\n",
            "string = NLP is hard and useless\n",
            "\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "negative sentiment ðŸ˜ž\n",
            "Subjectivity : 0.37083333333333335\n",
            "----------------------------------------------------------------------------------------------------\n",
            "string = NLP stands for Natural Language Processing\n",
            "\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "neutral sentiment ðŸ˜‘\n",
            "Subjectivity : 0.4\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}